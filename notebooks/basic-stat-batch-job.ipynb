{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create basic stats table\n",
    "Given a list of summoner names, we'll create a basic stats table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set notebook code preview\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "# Set display width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Row\n",
    "from collections import OrderedDict\n",
    "from pyspark.sql.functions import col, avg\n",
    "\n",
    "spark = SparkSession.builder.config('spark.driver.extraClassPath', './lib/postgresql-42.2.5.jar').getOrCreate()\n",
    "url = 'jdbc:postgresql://postgres:5432/lol'\n",
    "properties = {'user': 'lol', 'password': 'lol'}\n",
    "sqlc = SQLContext(spark.sparkContext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_summoners = ['name_here']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce  # For Python 3.x\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def unionAll(*dfs):\n",
    "    return reduce(DataFrame.unionAll, dfs)\n",
    "\n",
    "def convert_to_row(d: dict) -> Row:\n",
    "    return Row(**OrderedDict(sorted(d.items())))\n",
    "\n",
    "list_of_df = []\n",
    "list = []\n",
    "for summoner_name in list_of_summoners:\n",
    "    get_all_matches_query = f\"(select m.* from summoner s join matches map on s.id = map.summoner_id join match m on map.match_id = m.id where s.name = '{summoner_name}') a\"\n",
    "    matches_df = spark.read.jdbc(url=url, table=get_all_matches_query, properties=properties)\n",
    "    info_df = sqlc.read.json(matches_df.rdd.map(lambda r: r.info))\n",
    "\n",
    "    for info in info_df.collect():\n",
    "        game_stat = {}\n",
    "        game_stat['gameDuration'] = info.gameDuration/60\n",
    "        game_stat['gameId'] = info.gameId\n",
    "        game_stat['gameCreation'] = info.gameCreation\n",
    "        participant_id = 0\n",
    "\n",
    "        for participant in info.participantIdentities:\n",
    "            if participant.player.summonerName == summoner_name:\n",
    "                participant_id = participant.participantId\n",
    "        # found participantId\n",
    "        for p in info.participants: \n",
    "            if participant_id == p.participantId:\n",
    "                game_stat['summoner_name'] = summoner_name\n",
    "                game_stat['goldEarned'] = p.stats.goldEarned\n",
    "                game_stat['visionScore'] = p.stats.visionScore\n",
    "                game_stat['totalDamageDealt'] = p.stats.totalDamageDealt\n",
    "                game_stat['totalDamageTaken'] = p.stats.totalDamageTaken\n",
    "                game_stat['kills'] = p.stats.kills\n",
    "                game_stat['deaths'] = p.stats.deaths\n",
    "                game_stat['assists'] = p.stats.assists\n",
    "                game_stat['goldPerMinDeltas_10'] = p.timeline.goldPerMinDeltas.__getitem__(\"0-10\") if p.timeline.goldPerMinDeltas else 0            \n",
    "                game_stat['goldPerMinDeltas_20'] = p.timeline.goldPerMinDeltas.__getitem__('10-20') if p.timeline.goldPerMinDeltas else 0            \n",
    "                game_stat['goldPerMinDeltas_30'] = p.timeline.goldPerMinDeltas.__getitem__('20-30') if p.timeline.goldPerMinDeltas else 0\n",
    "                game_stat['creepsPerMinDeltas_10'] = p.timeline.creepsPerMinDeltas.__getitem__('0-10') if p.timeline.goldPerMinDeltas else 0\n",
    "                game_stat['creepsPerMinDeltas_20'] = p.timeline.creepsPerMinDeltas.__getitem__('10-20') if p.timeline.goldPerMinDeltas else 0\n",
    "                game_stat['creepsPerMinDeltas_30'] = p.timeline.creepsPerMinDeltas.__getitem__('20-30') if p.timeline.goldPerMinDeltas else 0\n",
    "                list.append(game_stat)\n",
    "\n",
    "                                \n",
    "df = spark.sparkContext.parallelize(list).map(convert_to_row).toDF()           \n",
    "df.show(100)\n",
    "df.createOrReplaceTempView('basic_stats')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df = df.select(avg(\"goldEarned\"), avg(\"visionScore\"), avg(\"totalDamageDealt\"), \n",
    "#                        avg(\"totalDamageTaken\"), avg(\"kills\"), avg(\"deaths\"), avg(\"assists\"),\n",
    "#                       avg(\"goldPerMinDeltas_10\"), avg(\"goldPerMinDeltas_20\"), avg(\"goldPerMinDeltas_30\"),\n",
    "#                       avg(\"creepsPerMinDeltas_10\"), avg(\"creepsPerMinDeltas_20\"), avg(\"creepsPerMinDeltas_30\"))\n",
    "\n",
    "spark.sql(\"select summoner_name, avg(kills) from basic_stats group by summoner_name\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
